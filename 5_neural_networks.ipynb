{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.neural_networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPX+dSRmnPR3GYUv5e4y0K3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PashaIanko/Kaggle.Restaurant-Revenue-Prediction/blob/main/5_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "gGXkxPdjiPnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MXngTKIEiIur"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PEP 8\n",
        "%%capture\n",
        "!pip install pycodestyle\n",
        "!pip install --index-url https://test.pypi.org/simple/ nbpep8\n",
        "\n",
        "from nbpep8.nbpep8 import pep8"
      ],
      "metadata": {
        "id": "xLwrK5kNiR5R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import module files"
      ],
      "metadata": {
        "id": "Ok2Fy438iVsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "def download_files(url_dict):\n",
        "    for file, url in url_dict.items():\n",
        "        print(f'Downloading {file}')\n",
        "        !wget -O {file} {url} {file}\n",
        "\n",
        "\n",
        "files = [\n",
        "    'path_manager.py',\n",
        "    'sklearn_utils.py',\n",
        "    'sklearn_transformers.py',\n",
        "    'model.py'\n",
        "]\n",
        "\n",
        "git_download_path = \\\n",
        "'https://raw.githubusercontent.com/PashaIanko/Kaggle.Restaurant-Revenue-Prediction/main/'\n",
        "url_dict = {file: git_download_path + file for file in files}\n",
        "download_files(url_dict)"
      ],
      "metadata": {
        "id": "IgjimCjIiUIZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import path_manager\n",
        "import sklearn_transformers\n",
        "import sklearn_utils\n",
        "import model\n",
        "\n",
        "def reload_all(modules_list):\n",
        "    for module in modules_list:\n",
        "        importlib.reload(module)\n",
        "\n",
        "reload_all(\n",
        "    [\n",
        "        path_manager,\n",
        "        sklearn_utils,\n",
        "        sklearn_transformers,\n",
        "        model\n",
        "    ]\n",
        ")\n",
        "\n",
        "from path_manager import PathManager\n",
        "\n",
        "from sklearn_utils import boxplot_regression\n",
        "from sklearn_utils import get_correlated_attributes\n",
        "from sklearn_utils import nan_statistics\n",
        "from sklearn_utils import visualize_datasets_distributions\n",
        "from sklearn_utils import print_model_cv_scores\n",
        "from sklearn_utils import plot_cv_results\n",
        "from sklearn_utils import fit_grid_search\n",
        "from sklearn_utils import fit_randomized_search\n",
        "\n",
        "from sklearn_transformers import ColumnDropper\n",
        "from sklearn_transformers import LogTransformer\n",
        "from model import Model"
      ],
      "metadata": {
        "id": "-ruqFgA1iYYb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixing seed"
      ],
      "metadata": {
        "id": "neqPcl1Cicjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "H5yjfP0riat9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup paths"
      ],
      "metadata": {
        "id": "dK48Xd-Cihk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "gdrive_path = '/content/gdrive/MyDrive/'\n",
        "\n",
        "COMPETITION_PATH = gdrive_path + 'ML/Competitions/5.RestaurantRevenue/'\n",
        "PREPROC_TRIAL = 2\n",
        "MODELS_TRIAL = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oAXUVsUigbc",
        "outputId": "417a0cd5-a5f7-4c43-db7e-63583e64aac3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "manager = PathManager(\n",
        "    competition_path=COMPETITION_PATH, \n",
        "    preprocessing_trial=PREPROC_TRIAL,\n",
        "    models_trial=MODELS_TRIAL\n",
        ")\n",
        "manager.setup_paths()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNKJpuiVikoM",
        "outputId": "d334260f-7077-4dda-9c59-c927907ed8d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ML/Competitions/5.RestaurantRevenue/Data/preproc_trial_2 already exists\n",
            "/content/gdrive/MyDrive/ML/Competitions/5.RestaurantRevenue/Models/trial_2 already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the data"
      ],
      "metadata": {
        "id": "-4lJhgCrip6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_test_path = os.path.join(\n",
        "    manager.data_trial_path,\n",
        "    'test_processed.csv'\n",
        ")\n",
        "\n",
        "df_test = pd.read_csv(\n",
        "    kaggle_test_path, index_col=[0]\n",
        ")\n",
        "df_test.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "SK7ToOYwinyO",
        "outputId": "70ebfea2-ca16-444d-ed8a-a008507107ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2        3         4         5         6  \\\n",
              "0  0.995545 -1.032819 -0.285964 -0.26814 -0.383325 -0.807152 -0.633614   \n",
              "1  0.995545 -0.334236 -0.285964 -0.26814 -0.383325  0.014161 -0.633614   \n",
              "\n",
              "          7         8         9  ...        34        35        36        37  \\\n",
              "0 -0.182156 -0.619713 -0.217343  ... -0.497002 -0.606797 -0.556056 -0.652386   \n",
              "1 -0.182156 -1.176974 -0.790338  ... -0.497002 -0.606797 -0.556056 -0.652386   \n",
              "\n",
              "    38   39   40   41        42        43  \n",
              "0  0.0  0.0  1.0  0.0  0.020451  0.693147  \n",
              "1  0.0  0.0  0.0  1.0  0.138344  0.693147  \n",
              "\n",
              "[2 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40853f2c-9943-4473-9dc7-3dae1433f1a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.995545</td>\n",
              "      <td>-1.032819</td>\n",
              "      <td>-0.285964</td>\n",
              "      <td>-0.26814</td>\n",
              "      <td>-0.383325</td>\n",
              "      <td>-0.807152</td>\n",
              "      <td>-0.633614</td>\n",
              "      <td>-0.182156</td>\n",
              "      <td>-0.619713</td>\n",
              "      <td>-0.217343</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.497002</td>\n",
              "      <td>-0.606797</td>\n",
              "      <td>-0.556056</td>\n",
              "      <td>-0.652386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020451</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.995545</td>\n",
              "      <td>-0.334236</td>\n",
              "      <td>-0.285964</td>\n",
              "      <td>-0.26814</td>\n",
              "      <td>-0.383325</td>\n",
              "      <td>0.014161</td>\n",
              "      <td>-0.633614</td>\n",
              "      <td>-0.182156</td>\n",
              "      <td>-1.176974</td>\n",
              "      <td>-0.790338</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.497002</td>\n",
              "      <td>-0.606797</td>\n",
              "      <td>-0.556056</td>\n",
              "      <td>-0.652386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.138344</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40853f2c-9943-4473-9dc7-3dae1433f1a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40853f2c-9943-4473-9dc7-3dae1433f1a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40853f2c-9943-4473-9dc7-3dae1433f1a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_sample = pd.read_csv(\n",
        "    os.path.join(manager.data_trial_path, 'test_sample_processed.csv'), \n",
        "    index_col=[0]\n",
        ")\n",
        "df_test_sample.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "hj6eJh9XitUV",
        "outputId": "7849cb65-b29d-47bf-dc6c-6ae7975b17f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.994059 -1.032819 -1.653875  0.688913 -1.382555 -0.807152 -0.633614   \n",
              "1  0.993564  0.015056  0.397991 -0.268140 -1.382555 -0.807152 -0.159426   \n",
              "\n",
              "          7         8         9  ...        34        35        36        37  \\\n",
              "0 -2.019553 -0.062452 -0.217343  ... -0.497002 -0.606797 -0.556056 -0.652386   \n",
              "1 -0.182156 -0.062452 -0.217343  ...  0.611695  0.655776  0.253599  0.511872   \n",
              "\n",
              "    38   39   40   41        42         43  \n",
              "0  0.0  0.0  1.0  0.0  0.071805  14.842280  \n",
              "1  0.0  0.0  0.0  1.0  0.112946  15.312391  \n",
              "\n",
              "[2 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f348a756-5400-471c-9674-ae54766abe64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.994059</td>\n",
              "      <td>-1.032819</td>\n",
              "      <td>-1.653875</td>\n",
              "      <td>0.688913</td>\n",
              "      <td>-1.382555</td>\n",
              "      <td>-0.807152</td>\n",
              "      <td>-0.633614</td>\n",
              "      <td>-2.019553</td>\n",
              "      <td>-0.062452</td>\n",
              "      <td>-0.217343</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.497002</td>\n",
              "      <td>-0.606797</td>\n",
              "      <td>-0.556056</td>\n",
              "      <td>-0.652386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071805</td>\n",
              "      <td>14.842280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.993564</td>\n",
              "      <td>0.015056</td>\n",
              "      <td>0.397991</td>\n",
              "      <td>-0.268140</td>\n",
              "      <td>-1.382555</td>\n",
              "      <td>-0.807152</td>\n",
              "      <td>-0.159426</td>\n",
              "      <td>-0.182156</td>\n",
              "      <td>-0.062452</td>\n",
              "      <td>-0.217343</td>\n",
              "      <td>...</td>\n",
              "      <td>0.611695</td>\n",
              "      <td>0.655776</td>\n",
              "      <td>0.253599</td>\n",
              "      <td>0.511872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.112946</td>\n",
              "      <td>15.312391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f348a756-5400-471c-9674-ae54766abe64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f348a756-5400-471c-9674-ae54766abe64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f348a756-5400-471c-9674-ae54766abe64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_trainval = pd.read_csv(\n",
        "    os.path.join(manager.data_trial_path, 'trainval_sample_processed.csv'), \n",
        "    index_col=[0]\n",
        ")\n",
        "df_trainval.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Bxe2-MRfiuqE",
        "outputId": "a3a525e2-a204-4907-c6b6-b33bf740928a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.994554 -0.334236 -0.285964 -1.225193 -0.383325  0.014161 -0.633614   \n",
              "1  0.993564 -0.683527 -0.285964 -1.225193  0.615905  1.656785  0.788952   \n",
              "\n",
              "          7         8         9  ...        34        35        36        37  \\\n",
              "0 -0.182156 -0.062452 -0.217343  ...  0.168216  0.655776  0.253599  1.094000   \n",
              "1 -0.182156 -0.619713 -0.790338  ... -0.497002 -0.606797 -0.556056 -0.652386   \n",
              "\n",
              "    38   39   40   41        42         43  \n",
              "0  0.0  0.0  0.0  1.0  0.132383  15.278005  \n",
              "1  1.0  0.0  1.0  0.0  0.365242  15.255171  \n",
              "\n",
              "[2 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3e885ec-422e-436f-af8a-761d8a768bc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.994554</td>\n",
              "      <td>-0.334236</td>\n",
              "      <td>-0.285964</td>\n",
              "      <td>-1.225193</td>\n",
              "      <td>-0.383325</td>\n",
              "      <td>0.014161</td>\n",
              "      <td>-0.633614</td>\n",
              "      <td>-0.182156</td>\n",
              "      <td>-0.062452</td>\n",
              "      <td>-0.217343</td>\n",
              "      <td>...</td>\n",
              "      <td>0.168216</td>\n",
              "      <td>0.655776</td>\n",
              "      <td>0.253599</td>\n",
              "      <td>1.094000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.132383</td>\n",
              "      <td>15.278005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.993564</td>\n",
              "      <td>-0.683527</td>\n",
              "      <td>-0.285964</td>\n",
              "      <td>-1.225193</td>\n",
              "      <td>0.615905</td>\n",
              "      <td>1.656785</td>\n",
              "      <td>0.788952</td>\n",
              "      <td>-0.182156</td>\n",
              "      <td>-0.619713</td>\n",
              "      <td>-0.790338</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.497002</td>\n",
              "      <td>-0.606797</td>\n",
              "      <td>-0.556056</td>\n",
              "      <td>-0.652386</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.365242</td>\n",
              "      <td>15.255171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3e885ec-422e-436f-af8a-761d8a768bc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3e885ec-422e-436f-af8a-761d8a768bc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3e885ec-422e-436f-af8a-761d8a768bc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val = df_trainval.values[:, :-1]\n",
        "Y_train_val = df_trainval.values[:, -1]\n",
        "\n",
        "X_test_sample = df_test_sample.values[:, :-1]  # test subsample from training data\n",
        "Y_test_sample = df_test_sample.values[:, -1]"
      ],
      "metadata": {
        "id": "veOATD3Ziw-V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define architecture"
      ],
      "metadata": {
        "id": "sG49pylnizqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "ffnn = Sequential(\n",
        "    [\n",
        "        layers.Input(shape=X_train_val.shape[1]),\n",
        "        layers.Dense(units=10, activation='relu'),\n",
        "        layers.Dense(units=10, activation='relu'),\n",
        "        layers.Dense(units=1, activation='linear')\n",
        "    ]\n",
        ")\n",
        "\n",
        "ffnn.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer='adam'\n",
        ")\n",
        "\n",
        "pep8(_ih)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HK78KOzi0_6",
        "outputId": "6f8d63fa-171a-40ac-b649-6cb848509568"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data treatment"
      ],
      "metadata": {
        "id": "L2B4fwOnjrrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler \n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
        "X_test_sample_scaled = scaler.transform(X_test_sample)"
      ],
      "metadata": {
        "id": "EQffrS7cjFBB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(X_train_val_scaled), np.max(X_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eskbzLUNj626",
        "outputId": "7708c6ce-d84d-4f89-e8a1-ea40ada670e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0000000000000002, 6.313725890298421)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run training"
      ],
      "metadata": {
        "id": "QPq0ZcZekNi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "stopper = EarlyStopping(\n",
        "    mode='min',\n",
        "    monitor='val_loss',\n",
        "    patience=10\n",
        ")\n",
        "\n",
        "history = ffnn.fit(\n",
        "    X_train_val_scaled,\n",
        "    Y_train_val,\n",
        "    validation_data=(\n",
        "        X_test_sample_scaled,\n",
        "        Y_test_sample\n",
        "    ),\n",
        "    batch_size=16,\n",
        "    epochs=500,\n",
        "    callbacks=[stopper]\n",
        ")\n",
        "\n",
        "pep8(_ih)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg8tsbnvkMnq",
        "outputId": "0b64b825-b286-4258-c7c9-30dd4e0f129f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 224.6500 - val_loss: 217.9234\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 220.9972 - val_loss: 213.4716\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 216.6369 - val_loss: 208.0625\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 211.6385 - val_loss: 201.2879\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 205.2004 - val_loss: 193.5347\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 197.3194 - val_loss: 184.2269\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 187.8901 - val_loss: 173.2811\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 176.4717 - val_loss: 160.7988\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 163.5483 - val_loss: 146.1921\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 148.7839 - val_loss: 130.5995\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 133.0635 - val_loss: 114.4960\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 116.3699 - val_loss: 98.7619\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 99.8360 - val_loss: 84.0839\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 83.9411 - val_loss: 71.7345\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 69.5324 - val_loss: 62.4898\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 57.8218 - val_loss: 56.7669\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 49.0547 - val_loss: 54.1216\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 42.7573 - val_loss: 52.7228\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 38.7564 - val_loss: 50.9663\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 35.8449 - val_loss: 48.9067\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 33.6281 - val_loss: 46.7503\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 31.5375 - val_loss: 43.7934\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 29.5733 - val_loss: 41.7155\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 27.7738 - val_loss: 40.0355\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.2342 - val_loss: 38.5516\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 24.7090 - val_loss: 36.4341\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 23.1396 - val_loss: 34.3811\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 21.8479 - val_loss: 32.4161\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 20.5315 - val_loss: 30.1354\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 19.2212 - val_loss: 27.4167\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.0834 - val_loss: 25.3506\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.9938 - val_loss: 23.9456\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 15.9761 - val_loss: 22.1242\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.9670 - val_loss: 20.6392\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.9640 - val_loss: 19.5804\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.2161 - val_loss: 18.4467\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.3931 - val_loss: 16.8186\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.5831 - val_loss: 15.6488\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.8959 - val_loss: 14.6608\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.2729 - val_loss: 13.6732\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.6522 - val_loss: 12.7713\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.0602 - val_loss: 11.8046\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.6033 - val_loss: 10.8609\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0196 - val_loss: 10.3051\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5426 - val_loss: 9.9068\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1762 - val_loss: 9.5070\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7855 - val_loss: 9.0152\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.4166 - val_loss: 8.6358\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0816 - val_loss: 8.1691\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7944 - val_loss: 7.7765\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5190 - val_loss: 7.4451\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2591 - val_loss: 7.2006\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0185 - val_loss: 6.9648\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7928 - val_loss: 6.7466\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5966 - val_loss: 6.5118\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3956 - val_loss: 6.3198\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2191 - val_loss: 6.1417\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0435 - val_loss: 5.9359\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8641 - val_loss: 5.7559\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7176 - val_loss: 5.5201\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5602 - val_loss: 5.3359\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4125 - val_loss: 5.2227\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3029 - val_loss: 5.1578\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1686 - val_loss: 5.0560\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0567 - val_loss: 4.8898\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9419 - val_loss: 4.7182\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8416 - val_loss: 4.5795\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7462 - val_loss: 4.4807\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6756 - val_loss: 4.3754\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5945 - val_loss: 4.3051\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5141 - val_loss: 4.2360\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4380 - val_loss: 4.1783\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3957 - val_loss: 4.1232\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3120 - val_loss: 4.0146\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2484 - val_loss: 3.9383\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1978 - val_loss: 3.8794\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1400 - val_loss: 3.8295\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0982 - val_loss: 3.7696\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0496 - val_loss: 3.6946\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0015 - val_loss: 3.6684\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9640 - val_loss: 3.6436\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9305 - val_loss: 3.5902\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8859 - val_loss: 3.4977\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8523 - val_loss: 3.4325\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8241 - val_loss: 3.3918\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7852 - val_loss: 3.3437\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7585 - val_loss: 3.3119\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7295 - val_loss: 3.2697\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7012 - val_loss: 3.2443\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6841 - val_loss: 3.2230\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6542 - val_loss: 3.1574\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6408 - val_loss: 3.0887\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6112 - val_loss: 3.0619\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5887 - val_loss: 3.0389\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5732 - val_loss: 3.0060\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5544 - val_loss: 2.9594\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5345 - val_loss: 2.9115\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5208 - val_loss: 2.8571\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5016 - val_loss: 2.8314\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4824 - val_loss: 2.8044\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4693 - val_loss: 2.7836\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4519 - val_loss: 2.7631\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4387 - val_loss: 2.7289\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4240 - val_loss: 2.6894\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4110 - val_loss: 2.6620\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4023 - val_loss: 2.6426\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3874 - val_loss: 2.6233\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3957 - val_loss: 2.6145\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3973 - val_loss: 2.5295\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3527 - val_loss: 2.5013\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3427 - val_loss: 2.4630\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3347 - val_loss: 2.4311\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3279 - val_loss: 2.3942\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3164 - val_loss: 2.3728\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3036 - val_loss: 2.3555\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2959 - val_loss: 2.3346\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2883 - val_loss: 2.3056\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2724 - val_loss: 2.2775\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2664 - val_loss: 2.2565\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2571 - val_loss: 2.2428\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2471 - val_loss: 2.2329\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2427 - val_loss: 2.2196\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2326 - val_loss: 2.2223\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2262 - val_loss: 2.1896\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2242 - val_loss: 2.1650\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2091 - val_loss: 2.1490\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2049 - val_loss: 2.1317\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1943 - val_loss: 2.1185\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1846 - val_loss: 2.0886\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1775 - val_loss: 2.0734\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1703 - val_loss: 2.0560\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1628 - val_loss: 2.0363\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1572 - val_loss: 2.0306\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1494 - val_loss: 2.0186\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1418 - val_loss: 2.0020\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1367 - val_loss: 1.9852\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1285 - val_loss: 1.9767\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1224 - val_loss: 1.9621\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1207 - val_loss: 1.9390\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1106 - val_loss: 1.9316\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1163 - val_loss: 1.9140\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0971 - val_loss: 1.9038\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0939 - val_loss: 1.8842\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1001 - val_loss: 1.8725\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0830 - val_loss: 1.8639\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0770 - val_loss: 1.8510\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0701 - val_loss: 1.8273\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0635 - val_loss: 1.8208\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0512 - val_loss: 1.8092\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0482 - val_loss: 1.8013\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0390 - val_loss: 1.7867\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0348 - val_loss: 1.7724\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0272 - val_loss: 1.7612\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0225 - val_loss: 1.7431\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0155 - val_loss: 1.7302\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0080 - val_loss: 1.7219\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0037 - val_loss: 1.7087\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9958 - val_loss: 1.7037\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9906 - val_loss: 1.6880\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9865 - val_loss: 1.6715\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9873 - val_loss: 1.6527\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9762 - val_loss: 1.6536\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9698 - val_loss: 1.6365\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9666 - val_loss: 1.6443\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9619 - val_loss: 1.6193\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9549 - val_loss: 1.5996\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9479 - val_loss: 1.5959\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9417 - val_loss: 1.5822\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9354 - val_loss: 1.5736\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9285 - val_loss: 1.5679\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9264 - val_loss: 1.5692\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9267 - val_loss: 1.5613\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9199 - val_loss: 1.5560\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9172 - val_loss: 1.5597\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9061 - val_loss: 1.5541\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9023 - val_loss: 1.5371\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8913 - val_loss: 1.5173\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8872 - val_loss: 1.5093\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8828 - val_loss: 1.5039\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8802 - val_loss: 1.4945\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8766 - val_loss: 1.4816\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8718 - val_loss: 1.4659\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8609 - val_loss: 1.4603\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8572 - val_loss: 1.4383\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8550 - val_loss: 1.4248\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8476 - val_loss: 1.4202\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8415 - val_loss: 1.4206\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8412 - val_loss: 1.4184\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8331 - val_loss: 1.4026\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8303 - val_loss: 1.3909\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8255 - val_loss: 1.3856\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8325 - val_loss: 1.3873\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8117 - val_loss: 1.3699\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8140 - val_loss: 1.3613\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8144 - val_loss: 1.3535\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8100 - val_loss: 1.3626\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7937 - val_loss: 1.3548\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7890 - val_loss: 1.3535\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7820 - val_loss: 1.3399\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7824 - val_loss: 1.3305\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7759 - val_loss: 1.3256\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7679 - val_loss: 1.3199\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7725 - val_loss: 1.3237\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7614 - val_loss: 1.3057\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7577 - val_loss: 1.2955\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7580 - val_loss: 1.2889\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7563 - val_loss: 1.2764\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.7429 - val_loss: 1.2720\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7365 - val_loss: 1.2634\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7329 - val_loss: 1.2547\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7305 - val_loss: 1.2522\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7244 - val_loss: 1.2397\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7278 - val_loss: 1.2270\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7266 - val_loss: 1.2139\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7228 - val_loss: 1.2065\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7105 - val_loss: 1.2048\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7065 - val_loss: 1.1970\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7096 - val_loss: 1.1861\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6997 - val_loss: 1.1737\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6923 - val_loss: 1.1777\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6887 - val_loss: 1.1800\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6910 - val_loss: 1.1862\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6836 - val_loss: 1.1711\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6747 - val_loss: 1.1617\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6680 - val_loss: 1.1499\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6653 - val_loss: 1.1389\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6619 - val_loss: 1.1306\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6575 - val_loss: 1.1218\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6581 - val_loss: 1.1140\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6477 - val_loss: 1.1160\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6478 - val_loss: 1.1127\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6539 - val_loss: 1.1126\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6380 - val_loss: 1.0906\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6366 - val_loss: 1.0879\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6348 - val_loss: 1.0855\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6261 - val_loss: 1.0800\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6232 - val_loss: 1.0786\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6213 - val_loss: 1.0783\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6209 - val_loss: 1.0673\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6108 - val_loss: 1.0567\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6189 - val_loss: 1.0527\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6082 - val_loss: 1.0472\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6030 - val_loss: 1.0557\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6005 - val_loss: 1.0443\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5947 - val_loss: 1.0413\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5930 - val_loss: 1.0342\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5870 - val_loss: 1.0231\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5886 - val_loss: 1.0125\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5885 - val_loss: 1.0097\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5781 - val_loss: 1.0024\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5724 - val_loss: 1.0021\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5700 - val_loss: 1.0004\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5622 - val_loss: 0.9910\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5712 - val_loss: 0.9857\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5640 - val_loss: 0.9826\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5528 - val_loss: 0.9839\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5534 - val_loss: 0.9938\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5533 - val_loss: 0.9759\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5447 - val_loss: 0.9755\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5428 - val_loss: 0.9610\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5359 - val_loss: 0.9566\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5338 - val_loss: 0.9524\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5313 - val_loss: 0.9499\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5266 - val_loss: 0.9370\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5233 - val_loss: 0.9279\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5247 - val_loss: 0.9164\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5191 - val_loss: 0.9060\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5144 - val_loss: 0.9021\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5110 - val_loss: 0.8934\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5128 - val_loss: 0.8837\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5058 - val_loss: 0.8857\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5043 - val_loss: 0.8824\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5012 - val_loss: 0.8712\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4973 - val_loss: 0.8680\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4939 - val_loss: 0.8613\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4919 - val_loss: 0.8580\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4889 - val_loss: 0.8575\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4843 - val_loss: 0.8531\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4822 - val_loss: 0.8457\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4798 - val_loss: 0.8395\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4790 - val_loss: 0.8275\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4788 - val_loss: 0.8347\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4765 - val_loss: 0.8193\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4742 - val_loss: 0.8088\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4686 - val_loss: 0.8136\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4658 - val_loss: 0.8095\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4630 - val_loss: 0.8015\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4608 - val_loss: 0.7925\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4600 - val_loss: 0.7951\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4523 - val_loss: 0.7869\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4483 - val_loss: 0.7909\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4457 - val_loss: 0.7961\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4457 - val_loss: 0.7999\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4436 - val_loss: 0.7866\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4395 - val_loss: 0.7786\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4350 - val_loss: 0.7726\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4330 - val_loss: 0.7701\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4349 - val_loss: 0.7599\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4272 - val_loss: 0.7509\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4274 - val_loss: 0.7520\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4240 - val_loss: 0.7406\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4203 - val_loss: 0.7415\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4248 - val_loss: 0.7510\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4171 - val_loss: 0.7382\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4141 - val_loss: 0.7331\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4119 - val_loss: 0.7289\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4093 - val_loss: 0.7261\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4096 - val_loss: 0.7226\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4102 - val_loss: 0.7310\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4021 - val_loss: 0.7190\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4078 - val_loss: 0.7155\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4007 - val_loss: 0.7048\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3974 - val_loss: 0.7064\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3950 - val_loss: 0.6956\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3915 - val_loss: 0.6962\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3902 - val_loss: 0.6908\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3874 - val_loss: 0.6872\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3820 - val_loss: 0.6850\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3845 - val_loss: 0.6866\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3800 - val_loss: 0.6863\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3764 - val_loss: 0.6981\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3866 - val_loss: 0.6744\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3771 - val_loss: 0.6727\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3726 - val_loss: 0.6685\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3682 - val_loss: 0.6711\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3680 - val_loss: 0.6680\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3661 - val_loss: 0.6587\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3651 - val_loss: 0.6499\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3686 - val_loss: 0.6462\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3626 - val_loss: 0.6462\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3749 - val_loss: 0.6527\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3572 - val_loss: 0.6301\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3601 - val_loss: 0.6260\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3629 - val_loss: 0.6338\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3449 - val_loss: 0.6203\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3517 - val_loss: 0.6174\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3446 - val_loss: 0.6195\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3467 - val_loss: 0.6193\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3407 - val_loss: 0.6250\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3412 - val_loss: 0.6177\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3513 - val_loss: 0.6112\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3417 - val_loss: 0.6124\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3340 - val_loss: 0.6057\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3323 - val_loss: 0.5963\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3315 - val_loss: 0.5909\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3344 - val_loss: 0.5875\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3308 - val_loss: 0.5822\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3288 - val_loss: 0.5860\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3235 - val_loss: 0.5783\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3224 - val_loss: 0.5747\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3195 - val_loss: 0.5793\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3182 - val_loss: 0.5819\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3173 - val_loss: 0.5821\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3203 - val_loss: 0.5795\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3158 - val_loss: 0.5783\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3160 - val_loss: 0.5832\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3142 - val_loss: 0.5620\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3104 - val_loss: 0.5630\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3092 - val_loss: 0.5597\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3073 - val_loss: 0.5559\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3038 - val_loss: 0.5534\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3031 - val_loss: 0.5516\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3009 - val_loss: 0.5450\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2989 - val_loss: 0.5439\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3005 - val_loss: 0.5468\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2976 - val_loss: 0.5401\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2947 - val_loss: 0.5468\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2938 - val_loss: 0.5371\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2925 - val_loss: 0.5325\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2910 - val_loss: 0.5319\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2921 - val_loss: 0.5296\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2891 - val_loss: 0.5286\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2880 - val_loss: 0.5261\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2876 - val_loss: 0.5294\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2853 - val_loss: 0.5312\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2858 - val_loss: 0.5234\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2841 - val_loss: 0.5189\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2823 - val_loss: 0.5173\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2805 - val_loss: 0.5166\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2793 - val_loss: 0.5102\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2766 - val_loss: 0.5048\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2761 - val_loss: 0.5078\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2758 - val_loss: 0.5081\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2773 - val_loss: 0.5065\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2749 - val_loss: 0.4947\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2743 - val_loss: 0.4894\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2712 - val_loss: 0.4880\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2686 - val_loss: 0.4857\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2670 - val_loss: 0.4863\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2679 - val_loss: 0.4831\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2643 - val_loss: 0.4822\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2657 - val_loss: 0.4739\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2651 - val_loss: 0.4758\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2680 - val_loss: 0.4728\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2636 - val_loss: 0.4827\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2676 - val_loss: 0.4724\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2598 - val_loss: 0.4721\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2588 - val_loss: 0.4714\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2577 - val_loss: 0.4743\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2577 - val_loss: 0.4650\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2571 - val_loss: 0.4551\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2550 - val_loss: 0.4611\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2547 - val_loss: 0.4742\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2529 - val_loss: 0.4628\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2520 - val_loss: 0.4582\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2522 - val_loss: 0.4543\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2479 - val_loss: 0.4485\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2506 - val_loss: 0.4471\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2539 - val_loss: 0.4582\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2431 - val_loss: 0.4455\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2475 - val_loss: 0.4386\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2460 - val_loss: 0.4363\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2434 - val_loss: 0.4349\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2498 - val_loss: 0.4384\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2421 - val_loss: 0.4222\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2487 - val_loss: 0.4242\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2469 - val_loss: 0.4544\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2477 - val_loss: 0.4269\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2424 - val_loss: 0.4294\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2343 - val_loss: 0.4282\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2402 - val_loss: 0.4271\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2396 - val_loss: 0.4143\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2341 - val_loss: 0.4168\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2353 - val_loss: 0.4170\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2331 - val_loss: 0.4137\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2353 - val_loss: 0.4122\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2322 - val_loss: 0.4211\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2308 - val_loss: 0.4177\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2315 - val_loss: 0.4186\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2281 - val_loss: 0.4196\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2298 - val_loss: 0.4069\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2268 - val_loss: 0.4079\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2267 - val_loss: 0.4096\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2279 - val_loss: 0.4058\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2306 - val_loss: 0.4030\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2282 - val_loss: 0.3999\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2231 - val_loss: 0.3994\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2257 - val_loss: 0.3979\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2199 - val_loss: 0.3950\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2242 - val_loss: 0.3920\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2209 - val_loss: 0.3943\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2199 - val_loss: 0.3950\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2191 - val_loss: 0.3913\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2186 - val_loss: 0.3913\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2171 - val_loss: 0.3921\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2197 - val_loss: 0.3903\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2171 - val_loss: 0.3891\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2170 - val_loss: 0.3926\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2168 - val_loss: 0.3922\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2156 - val_loss: 0.3824\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2167 - val_loss: 0.3853\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2165 - val_loss: 0.3876\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2212 - val_loss: 0.3786\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2194 - val_loss: 0.3862\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2125 - val_loss: 0.3827\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2115 - val_loss: 0.3856\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2093 - val_loss: 0.3829\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2096 - val_loss: 0.3807\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2099 - val_loss: 0.3801\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2087 - val_loss: 0.3783\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2074 - val_loss: 0.3791\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2067 - val_loss: 0.3807\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2034 - val_loss: 0.3777\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2064 - val_loss: 0.3778\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2096 - val_loss: 0.3936\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2040 - val_loss: 0.3809\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2030 - val_loss: 0.3816\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2000 - val_loss: 0.3868\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2034 - val_loss: 0.3842\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2001 - val_loss: 0.3879\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2069 - val_loss: 0.3853\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1978 - val_loss: 0.3902\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2024 - val_loss: 0.3836\n",
            "cell_content.py:1:53: W291 trailing whitespace\n",
            "cell_content.py:16:30: W291 trailing whitespace\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_ffnn_history(fit_history):\n",
        "    _, ax = plt.subplots()\n",
        "    \n",
        "    plot_params = dict(\n",
        "        marker='o',\n",
        "        markevery=10,\n",
        "        markerfacecolor='white'\n",
        "    )\n",
        "\n",
        "    ax.plot(\n",
        "        history.history['loss'], \n",
        "        label='train loss',\n",
        "        **plot_params\n",
        "    )\n",
        "    ax.plot(\n",
        "        history.history['val_loss'], \n",
        "        label='validation loss',\n",
        "        **plot_params\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.set_ylabel('Metrics')\n",
        "    ax.set_title('Learning curve')\n",
        "\n",
        "    ax.legend()\n",
        "    ax.grid()\n",
        "\n",
        "plot_ffnn_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FijK7fQDk3iX",
        "outputId": "0b4149ff-3b7f-42c3-d378-ca02c1387163"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnO5CFABIQxKAgshoWFbUK1JaK9iciKFK9aq+3Vi9Wva0K1rZiK7eoVC0V7bWuVatVqOKCxaUJtHUDFFlEZJF9CVsge0jy/f0xJ3GAmWxkMknO+/l4zGNmvud8z/meg+Y937N8jznnEBERAYiJdgNERKT5UCiIiEg1hYKIiFRTKIiISDWFgoiIVFMoiIhINYWCSD2Y2blmtiba7RCJFNN9CtJSmNlG4L+cc+9Fuy0irZV6CiJBzCw22m04Vq1hGyR6FArS4plZjJlNNbP1ZrbXzF42sw5B018xs51mdsDMFplZ/6Bpz5jZY2Y238wKgVFmttHMbjOz5V6dv5pZkjf/SDPbGlQ/7Lze9DvMbIeZbTez/zIzZ2a9wmxHBzN72pt3v5m95pVfa2b/OmLe6uWE2IbbvO2NDZp/nJktr8v+En9TKEhr8BPgEmAEcDywH5gdNP1toDfQGfgUeOGI+j8ApgMpQNUf38uBC4CewCDg2hrWH3JeM7sA+CnwHaAXMLKW7XgOaAv099r6UC3zh9uG3wOFwLePmP4X73Nt+0t8TKEgrcENwF3Oua3OuVJgGjDBzOIAnHNPOefyg6adZmZpQfXnOef+7ZyrdM6VeGWznHPbnXP7gDeArBrWH27ey4GnnXOrnHNF3rpDMrOuwBjgBufcfufcIefcwnrsgyO34UVgkrfsFOBCrwxq2V/ibwoFaQ1OBF41szwzywNWAxVAhpnFmtkM71DJQWCjV6dTUP0tIZa5M+hzEZBcw/rDzXv8EcsOtZ4qJwD7nHP7a5inJkcu+y/ApWaWCFwKfOqc2+RNC7u/GrhuaUUUCtIabAHGOOfaB72SnHPbCBw2GUvgEE4akOnVsaD6kboEbwfQPej7CTXMuwXoYGbtQ0wrJHBYCQAz6xJinsO2wTn3BbCJQO8j+NBR1brC7S/xOYWCtDTxZpYU9IoD/ghMN7MTAczsODMb682fApQCewn8Yf3fJmzry8APzayvmbUFfhluRufcDgLnPh41s3Qzizez87zJnwP9zSzLO4k9rY7r/wtwC3Ae8EpQeU37S3xOoSAtzXygOOg1jcCJ1deBd8wsH/gIONOb/88EfjFvA77wpjUJ59zbwCwgG1gXtO7SMFX+AzgEfAnkArd6y/kK+DXwHrCWb06G1+ZFAieT/+Gc2xNUXtP+Ep/TzWsiTcTM+gIrgUTnXHm02yMSinoKIhHk3R+QaGbpwH3AGwoEac4UCiKR9WMCh4LWE7jC58boNkekZjp8JCIi1dRTEBGRai36DsZOnTq5zMzMBtUtLCykXbt2jdugFsbv+8Dv2w/aB37d/qVLl+5xzh0XalqLDoXMzEyWLFnSoLo5OTmMHDmycRvUwvh9H/h9+0H7wK/bb2abwk3T4SMREammUBARkWoKBRERqdaizymISNM7dOgQW7dupaSkpPaZm7m0tDRWr14d7WZETFJSEt27dyc+Pr7OdRQKIlIvW7duJSUlhczMTMys9grNWH5+PikpKdFuRkQ459i7dy9bt26lZ8+eda7nu8NH85ZtY/RDC/nPBYWMfmgh85ZptGCR+igpKaFjx44tPhBaOzOjY8eO9e7R+aqnMG/ZNma+s4b7xg/i9MwOLN64jylzlwMwNqtblFsn0nIoEFqGhvw7+aqnMDt7HfeNH8TZJ3ciPjaGs0/uxH3jBzE7e120myYi0iz4KhTW5RZwemaHw8pOz+zAutyCKLVIROorLy+PRx99tEF1L7zwQvLy8uo8/7Rp05g5c2aD1tVS+SoUenVOZvHGfYeVLd64j16da3r8rogci6rzeCfd+VajnMerKRTKy2selXz+/Pm0bx/qiadSxVehMHlUL6bMXc4H6/dwqKKSD9bvYcrc5Uwe1SvaTRNplarO4027uD9r7h3DtIv7M/OdNccUDFOnTmX9+vVkZWVx++23k5OTw7nnnsvFF19Mv379ALjkkksYOnQo/fv35/HHH6+um5mZyZ49e9i4cSN9+/blJz/5Cf3792f06NEUFxfXuN5ly5YxfPhwBg0axLhx49i/fz8As2bNol+/fgwaNIgrrrgCgIULF5KVlUVWVhaDBw8mPz+/wdvb1Hx1onlsVje6bX2LE175KbElm8hM6MFDgyYzLOvb0W6aSIt0zxur+GL7wbDTv9qVz+wrh3D2yZ0Aqs/jTX7hU/7y8eaQdfodn8rd/69/2GXOmDGDlStXsmzZMiAwftGnn37KypUrqy+9fOqpp+jQoQPFxcWcfvrpjB8/no4dOx62nLVr1/LEE0/wzDPPcPnllzN37lyuuuqqsOu9+uqr+cMf/sCIESP41a9+xT333MPDDz/MjBkz+Prrr0lMTKw+NDVz5kxmz57NOeecQ0FBAUlJSWGX29z4qqfAijkMW/cIGRNnEfPLXI6f9AeGrnsEVsyJdstEWqW8okMhz+PlFR1q1PWcccYZh12LP2vWLE477TSGDx/Oli1bWLt27VF1evbsyaBBgwAYOnQoGzduDLv8AwcOkJeXx4gRIwC45pprWLRoEQCDBg3iyiuv5PnnnycuLvA7+5xzzuGnP/0ps2bNIi8vr7q8JWg5LW0Mi2bC2Eeg53mB7z3Pw8Y+AvPvgIETots2kRaopl/0AKMfWsjijfuqewoQOI/XOyOZv/74rEZrR/Dw1zk5Obz33nt8+OGHtG3blpEjR4a8Vj8xMbH6c2xsbK2Hj8J56623WLRoEW+88QbTp09nxYoVTJ06lYsuuoj58+dzzjnnsGDBAk499dQGLb+p+aunsGcN9DjiP8QeZwXKRaTRReI8XkpKSo3H6A8cOEB6ejpt27blyy+/5KOPPmrwuqqkpaWRnp7OP//5TwCee+45RowYQWVlJVu2bGHUqFHcd999HDhwgIKCAtavX8/AgQOZMmUKp59+Ol9++eUxt6Gp+Kun0KkPbP7wm54CBL536hO9Nom0YlU3hU57fRXrcgvo1TmZ20b3OaabRTt27Mg555zDgAEDGDNmDBdddNFh0y+44AL++Mc/0rdvX/r06cPw4cOPaRuqPPvss9xwww0UFRVx0kkn8fTTT1NRUcFVV13FgQMHcM5x88030759e375y1+SnZ1NTEwM/fv3Z8yYMY3ShibhnGuxr6FDh7p6Wf6Kcw8NdG7DQufKy5zbsNCVzuwfKPeh7OzsaDchqvy+/c41bB988cUXjd+QKDl48GC0mxBxof69gCUuzN9Vf/UUqs4bzL8Dt/tLDiW259HE67lV5xNERAC/nVOAQDBM/ojczudSWJnIswXDot0iEZFmw3+h4Clu04W0Q7kUFBWzr7As2s0REWkWfBwKXYmhkm62m237G3YpmohIa+PbUChJ6gLAiZbL9gMKBRER8HEoFLcJhEIP28WOPIWCiAj4OBTKEtrjYuLpHrOfHQda/rNmRSS85OTASMjbt29nwoTQVxuOHDmSJUuW1Lichx9+mKKiourv9R2KO5zmNES3b0MBi8FSutAj4SDbFQoikbNiDsweDvekB96jONbY8ccfz5w5DV//kaHQGofi9m8oACRncHzsAXbqnIJIZKyYA+//Gi68H36RG3h//9fHFAxTp05l9uzZ1d+rfmUXFBRw/vnnM2TIEAYOHMi8efOOqrtx40YGDBgAQHFxMddeey19+/Zl3Lhxh419dOONNzJs2DD69+/P3XffDQQG2du+fTujRo1i1KhRwDdDcQM8+OCDDBgwgAEDBvDwww9Xr69v37786Ec/ajFDdPvr5rUjpXThuN0r2VOgS1JFGuTtqbBzRfjpu1fDZc8cNgglYx+BV66FJU+HrtNlIIyZEXaREydO5NZbb2Xy5MkAvPzyyyxYsICkpCReffVVUlNT2bNnD8OHD+fiiy8O+5zixx57jLZt27J69WqWL1/OkCFDqqdNnz6dDh06UFFRwfnnn8/y5cu5+eabefDBB8nOzqZTp06HLWvp0qU8/fTTfPzxxzjnOPPMMxkxYgTp6emsXbuWF198kT/96U8tYojuiPUUzOwEM8s2sy/MbJWZ3eKVdzCzd81srfee7pWbmc0ys3VmttzMhtS8hkaQ0pX0ir3szi+N+KpEfKloX+hBKIv2hZ6/DgYPHkxubi7bt2/n888/Jz09nRNOOAHnHD//+c8ZNGgQ3/nOd9i2bRu7du0Ku5xFixYxceJEIDD8ddUw2hAImiFDhjB48GBWrVrFF198UWOb/vWvfzFu3DjatWtHcnIyl156afXgeT179iQrKwtoGUN0R7KnUA78zDn3qZmlAEvN7F3gWuB959wMM5sKTAWmAGOA3t7rTOAx7z1yUrrQpiKfQ6VFFJWV0zbB3x0nkXqr4Rc9EDiHEGoQyuNOhR++1eDVXnbZZcyZM4edO3dW/2F/4YUX2L17N0uXLiU+Pp7MzMyQQ2bX5uuvv2bmzJksXryY9PR0rr322gYtp0pLG6I7Yj0F59wO59yn3ud8YDXQDRgLPOvN9ixwifd5LPBnb7ymj4D2ZtY1Uu0DICVwWWpn28+efB1CEml0590G826CrxdBxaHA+7ybAuXHYOLEibz00kvMmTOHyy67DAj8yu7cuTPx8fFkZ2ezadOmmpt23nm88sorAKxcuZLly5cDcPDgQdq1a0daWhq7du3i7bffrq4Tbtjuc889l9dee42ioiIKCwt59dVXOffcc+u9Xc1hiO4m+WlsZpnAYOBjIMM5t8ObtBPI8D53A7YEVdvqle0IKsPMrgeuB8jIyCAnJ6dBbSooKODzfbmcBnQmjwWLPqR3emyDltVSFRQUNHj/tQZ+335o2D5IS0ur+wnNzO8Rd3YxiW/dhu1di+vYm9Kzb6c883twDCdFe/TowYEDB+jSpQvJycnk5+czduxYLr/8cvr378/gwYM55ZRTKCgoqG5rfn4+BQUFVFZWkp+fz1VXXcW//vUv+vTpQ58+fcjKyqKwsJAhQ4YwYMAATjnlFLp3786ZZ55JSUkJ+fn5XH311YwePZquXbvy1ltv4ZyjoKCA3r17M2nSJIYNC4yldvXVV9OrVy82bdpUvT6A0tJSSktLj9p/paWlxMfHk5+fz6OPPsqtt95KcXExmZmZPProo+Tl5TFp0iQOHjyIc44f//jHxMbGcv/99/PPf/6TmJgYTj31VL71rW8dteySkpL6/RuHGz61sV5AMrAUuNT7nnfE9P3e+5vAt4LK3weG1bTseg+dHSQ7O9u5nSuduzvV3XjnL9zbK7Y3eFktld+Hjvb79junobM1dPbRr4hekmpm8cBc4AXn3N+84l1Vh4W891yvfBtwQlD17l5Z5KQEjk5l2H526wokEZGIXn1kwJPAaufcg0GTXgeu8T5fA8wLKr/auwppOHDAfXOYKTLapONiE8iwPPI0UqqISETPKZwD/AewwsyWeWU/B2YAL5vZdcAm4HJv2nzgQmAdUAT8MIJtCzDDkrvQrTyPT4sUCiJ15ZwLe/2/NB+BI0X1E7FQcM79Cwj3X835IeZ3wORItSeslAyOz8/jffUUROokKSmJvXv30rFjRwVDM+acY+/evfW+oU0X5rc7jg62mn1Fh6LdEpEWoXv37mzdupXdu3dHuynHrKSkpFHuAm6ukpKS6N69e73qKBTadqA9B9mvnoJIncTHx9OzZ89oN6NR5OTkMHjw4Gg3o1nx94B4AG07kVJ5kH0FGupCRESh0LYjce4QZcUHo90SEZGoUyi07QhA4qE8Sg5VRLkxIiLRpVDwQqEjB8kvKY9yY0REokuh4IVCuuVzsERXIImIvykU2nYAoCP56imIiO8pFNqkA5BqheSrpyAiPqdQSEwFIJUiDharpyAi/qZQiI2jMiGZVCtST0FEfE+hAJCURiqFOqcgIr6nUAAsKY1UK9LVRyLiewoFwJLakx5brJ6CiPieQgEgKY32VsTBYvUURMTfFAoQOKdgRRxUT0FEfE6hAJCURrLTfQoiIgoFgKQ02rpC8ov1TAUR8TeFAkBSGjE4Kko0fLaI+JtCASApLfBeciC67RARiTKFAlSHQmzZQZxzUW6MiEj0KBSgOhRSXBGFZXrQjoj4l0IBqkMh1Qp1r4KI+JpCAb4JBYp0V7OI+JpCAQ7rKeheBRHxM4UCHP5MBYWCiPiYQgECz1SIr3qmgg4fiYh/KRQ8znumQpGuPhIRH1MoVElKJdWKKCxVT0FE/Euh4IlJTKYtJRSWqqcgIv6lUPBYQjLJMaUUlamnICL+pVCokphMipVSqFAQER9TKFRJSKat6fCRiPibQqFKQjvvnIJ6CiLiXwqFKgntaONKdEmqiPhaxELBzJ4ys1wzWxlUNs3MtpnZMu91YdC0O81snZmtMbPvRapdYSUkk0gZRSWlTb5qEZHmIpI9hWeAC0KUP+Scy/Je8wHMrB9wBdDfq/OomcVGsG1HS2gHgCvLb9LViog0JxELBefcImBfHWcfC7zknCt1zn0NrAPOiFTbQqoKhdLCJl2tiEhzEheFdd5kZlcDS4CfOef2A92Aj4Lm2eqVHcXMrgeuB8jIyCAnJ6dBjSgoKDisbuddm+kHlBflNXiZLc2R+8Bv/L79oH3g9+0PpalD4THgN4Dz3n8H/Gd9FuCcexx4HGDYsGFu5MiRDWpITk4Oh9VdUwKrIcGV0dBltjRH7QOf8fv2g/aB37c/lCa9+sg5t8s5V+GcqwT+xDeHiLYBJwTN2t0razre4aOEymLKyiubdNUiIs1Fk4aCmXUN+joOqLoy6XXgCjNLNLOeQG/gk6ZsW1UotKVEQ12IiG9F7PCRmb0IjAQ6mdlW4G5gpJllETh8tBH4MYBzbpWZvQx8AZQDk51zTXvDQEIyAMmUUFhWQfu2Tbp2EZFmIWKh4JybFKL4yRrmnw5Mj1R7alXVU7ASinRXs4j4lO5oruKFQjtKKFAoiIhPKRSqeIePAucUNNSFiPiTQqFKbByVsYm0s1INiicivqVQCOLivZFSdfWRiPiUQiFYQjvaWbGeqSAivqVQCJaYTDv0SE4R8S+FQpAD5QmkxJTy27e/ZPRDC5m3rGlvqhYRibZoDIjXLM1bto3jD8DAzrF8dcMYFm/cx5S5ywEYmxVybD4RkVZHPQXP7Ox1nNQtg1QrIz42hrNP7sR94wcxO3tdtJsmItJkFAqedbkFpLdPh7KC6rLTMzuwLreghloiIq2LQsHTq3MyuaVxh4XC4o376NU5OYqtEhFpWgoFz+RRvfjHhkIqSgs4VFHJB+v3MGXuciaP6hXtpomINJk6hYKZ3WJmqRbwpJl9amajI924pjQ2qxuDe3UntqKUvne9ybTXV3Hb6D46ySwivlLXnsJ/OucOAqOBdOA/gBkRa1WU9O0ReNzDwM7xvPM/IxQIIuI7dQ0F894vBJ5zzq0KKms9vJFSg88riIj4SV1DYamZvUMgFBaYWQrQ+p5ZmZgCgJUVRrkhIiLRUdeb164DsoANzrkiM+sI/DByzYoSr6cQc0ihICL+VNeewlhgvXMuz/teAZwUmSZFkRcKcRVFVFa6KDdGRKTp1TUU7nbOHaj64oXD3ZFpUhRVPZKTEooPaaRUEfGfuoZCqPla37hJ3tPX2unpayLiU3UNhSVm9qCZney9HgSWRrJhUVHVUzANny0i/lTXUPgJUAb81XuVApMj1aio8UJBPQUR8as6HQJyzhUCUyPcluj7agEktOOXPE/Zy5/At++AgROi3SoRkSZTYyiY2cPOuVvN7A3gqMtxnHMXR6xlTW3FHMj+X5j0EtbjLBI3fwjzbgpMUzCIiE/U1lN4znufGemGRN2imTD2Eeh5XuB7z/MC3+ertyAi/lFjKDjnlppZLHC9c+7KJmpTdOxZAz3OOrysx1mBchERn6j1RLNzrgI40cwSmqA90dOpD2z+8PCyzR8GykVEfKKu9xpsAP5tZq8D1WNAOOcejEirouG82wLnEMY+EughVJ1TOP9X0W6ZiEiTqWsorPdeMUCKV9a6xoHwzhu4V66Fon3kp5xM6uhf6XyCiPhKXUPhC+fcK8EFZnZZBNoTXQMnYKte5cvVy3m17/PcObBvtFskItKk6nrz2p11LGv5EpJJsWLdvCYivlTbfQpjCDxDoZuZzQqalAq0znEgEtrRllIKNcyFiPhQbYePtgNLgIs5fKyjfOB/ItWoqEpoFxglVT0FEfGh2u5T+Bz43Mz+4s3bwznXui/cT0gmkTKKS8ui3RIRkSZX13MKFwDLgL8DmFmWd3lq65MYGD7bleZHuSEiIk2vrqEwDTgDyANwzi0DetZUwcyeMrNcM1sZVNbBzN41s7Xee7pXbmY2y8zWmdlyMxvSoK1pDN5IqZWleiSniPhPXUPhUPCT1zy13afwDIEeRrCpwPvOud7A+3wz8uoYoLf3uh54rI7tanzeg3ZiDhVErQkiItFS11BYZWY/AGLNrLeZ/QH4oKYKzrlFwL4jiscCz3qfnwUuCSr/swv4CGhvZl3r2LbG5YWClamnICL+U9eb134C3EXg4TovAguA3zRgfRnOuR3e551Ahve5G7AlaL6tXtkOjmBm1xPoTZCRkUFOTk4DmgEFBQUh67bfv5YswJUebPCyW4pw+8Av/L79oH3g9+0Ppa4P2SkiEAp3NdaKnXPOzOo9VIZz7nHgcYBhw4a5kSNHNmj9OTk5hKy7LRU+h8TKEkaMGIGZNWj5LUHYfeATft9+0D7w+/aHUtvNazVeYdSAh+zsMrOuzrkd3uGhXK98G3BC0HzdvbKmlxgY2inJlVBaXklSfGxUmiEiEg219RTOInBY50XgY+BYfza/DlwDzPDe5wWV32RmLwFnAgeCDjM1rarnNFvgBjaFgoj4SW2h0AX4LjAJ+AHwFvCic25VbQs2sxeBkUAnM9sK3E0gDF42s+uATcDl3uzzCQynsQ4oAn5Y7y1pLFWhQAmFZeWkt2vdj5EQEQlW2x3NFQRuWPu7mSUSCIccM7vHOfdILXUnhZl0foh5HTC5bk2OMO/qo3Ya6kJEfKjWE81eGFxEIBAygVnAq5FtVhTFxFIRm0Tb8hKNlCoivlPbieY/AwMIHN65xzm3sqb5W4vKuHYkl5ZopFQR8Z3aegpXEXj85i3AzUGXZxqBoz6pEWxb1FQmtKNtkQ4fiYj/1HZOoa53PLcuCe28E80KBRHxF3/+0a9NQrJ3olmHj0TEXxQKIcQkJtPOSigsVU9BRPxFoRBCTFJy4OlrhxQKIuIvCoUQYhKTSbYSCkt1+EhE/EWhEIIlppJsxbpPQUR8R6EQSlIqyRRTWKLnNIuIvygUQklMJQZHeYme0ywi/qJQCCUpcE9eZfGRTyAVEWndFAqhJKUBYKUHo9wQEZGmpVAIJTHQU7BSHT4SEX9RKITi9RRiy9RTEBF/USiE4vUU4svVUxARf1EohOL1FBLKC6LcEBGRpqVQCMW7+qhtZRGl5bqBTUT8Q6EQSlwSFRZHqhVqUDwR8RWFQihmlCWkkUahxj8SEV9RKIRRntiBDpZPgUJBRHxEoRBGRZsOpFs++SUKBRHxD4VCOG060oF8DhYfinZLRESajEIhjJjkTqRbPgdLFAoi4h9x0W5AcxWX3Il25HOwqDTaTRERaTLqKYSRmHocseYoK9gX7aaIiDQZhUIYscnHAVCRvzvKLRERaToKhXCSOwMQU7gzyg0REWk6CoVw0k8EoE3htig3RESk6SgUwkntTgUxpJQoFETEPxQK4cTGsS+uM+1Ld0S7JSIiTUahUIO8hC50LNc5BRHxD4VCDfYn96JXxddQrnsVRMQfFAo12NP5bNpaKaUbPoh2U0REmoRCoQbF3c6mxMVT/tlfot0UEZEmEZVQMLONZrbCzJaZ2RKvrIOZvWtma7339Gi0LVhqWgeeq/gubb+cA/s3Rrs5IiIRF82ewijnXJZzbpj3fSrwvnOuN/C+9z2qOiYn8FT5GHAOlqm3ICKtX3M6fDQWeNb7/CxwSRTbAkDHdgnsoCO7jjsbPnsBKvVoThFp3cw51/QrNfsa2A844P+cc4+bWZ5zrr033YD9Vd+PqHs9cD1ARkbG0JdeeqlBbSgoKCA5ObnGeYrLHTe+V8Tzxz3Pt0oX4sqKKU09kQ3dLiU347wGrbc5qcs+aM38vv2gfeDX7R81atTSoKM0h3PONfkL6Oa9dwY+B84D8o6YZ39tyxk6dKhrqOzs7FrnqaysdLf96heudGZ/5zYsdK68LPD+0EDnlr/S4HU3F3XZB62Z37ffOe0Dv24/sMSF+bsalcNHzrlt3nsu8CpwBrDLzLoCeO+50WhbMDPjtjZvkHDpo9DzPIiND7yPfQQWzYx280REGl2Th4KZtTOzlKrPwGhgJfA6cI032zXAvKZuWyidSzZBj7MOL+xxFuxZE50GiYhEUDSevJYBvBo4bUAc8Bfn3N/NbDHwspldB2wCLo9C246S164n6Zs/DPQQqmz+EDr1iV6jREQipMlDwTm3ATgtRPle4Pymbk9tPu7+Q86bcyNtJzwW6CFs/hDm3QTn/yraTRMRaXR6RnMtivqMY+rKnfzuzduI37cW4tvA+dNg4IRoN01EpNE1p/sUmqVTMlJ4veJsFox4DW5aAmWFUHog2s0SEYkIhUItemckExdjrN5xEDqeDD1HwJJnoKI82k0TEWl0CoVaJMbFcvJxyazekR8oOONHcHArrF0Q3YaJiESAQqEOTjshjU8376ey0sEpYyC1Gyx+ItrNEhFpdAqFOkiIi6GsvJJed81n9Kx/s7rbeFj/D9i7PtpNExFpVAqFWsxbto2cNbt54pphrLl3DNMu7s+dG0/DEQPL/xrt5omINCqFQi1mZ6/j/gmDOPvkTsTHxnD2yZ24Y8JIPosdCCteCQyrLSLSSigUarEut4DTMzscVnZ6ZgdeLjkD9m2A7Z9FqWUiIo1PoVCLXp2TWbxx32Flizfu46uOoyAmHlbOjVLLREQan2j29C8AAA92SURBVEKhFpNH9WLK3OV8sH4Phyoq+WD9HqbMWc41386C3qMDoaCH74hIK6FhLmoxNqsbANNeX8W63AKS4mO5YcRJgfK48bDmLdjyCZx4Vi1LEhFp/tRTqIOxWd14539GsOzu0QBs3lccmHDy+WAxgctTRURaAYVCPaQmxTNhaHdeX7ad3PwSaNMe2mcGbmS7Jx1mD4cVc6LdTBGRBlMo1NO1Z2dSVlHJ8x9tDgRARSlc/iz8IhcuvB/e/7WCQURaLIVCPZ10XDLf7ZfBM//+msqFD8C4P+pRnSLSaigUGuCW83tzsKQc2/uVHtUpIq2KQqEBBnRL47v9MtgR3yPwJLZgelSniLRgCoUGuuX83swo/D6HXp0MXy+CikOB93k3wXm3Rbt5IiINovsUGmhAtzQq+o3nji9hyks3k1G6CUtow4ZuF3OSHtUpIi2UegrHYFhmOv9MHMmGy9+j/K5cCpJ70v7r+bz98cpoN01EpEEUCsfgxU82M2vS4MAIqvHxJE98nPYxRcS994toN01EpEEUCsfgqBFUM/rjzvgxo8oWwv5N0WuYiEgDKRSOQagRVD87fiKVFgt/n6pnLYhIi6NQOAahRlC9ef5uvup/K6yZDw8P0vAXItKi6OqjY3DkCKqpbeIpPVRB2nHdIbkLXDI7cDPb5g8Dl6oC6MokEWnGFArHaGxWt+pw2Lq/iIn/9xGxHzwEk/4UGPYCvhn+Yv4dCgURadZ0+KgRdU9vy0vXD6dL2WYNfyEiLZJCoZGd0KEtRaknhxz+ojglMyptEhGpK4VCBPzh0MVUvHb48BduznUkHNwIb/0MPnkicPJZJ6FFpJnROYUI+FPeUG6/4tTAOYQ9a6BTHyrOvZ2X3lrAVUuexrXtiE14svokdPmrk7/5h1g0s7oO592mcxAi0qQUChHQq3MynySfydmTL68u+2T9HmbE9OCipLWkT3jksJPQceNmU/bydSQktgmckA51xdKKOQoMEYk4hUIEVN2/cN/4QZye2YHFG/dxx5zlnNolhbRdW0KehE6oKISxT4a+YgkCT3QLFRgQOiwUIiLSAAqFCDjy/oVenZO5/Xt9GJvVja3Te9B984ff/PEH2PwhrqwICxEWbveX2N+nwoSnjg6Mv/2Icksgbtzsww9FbfkYvlpQa69jxJ41sKqOQRJuWkPqiEizpVCIkOD7F4I9FzeeO16bTGzQjW0Vr03mYEIX0kOERWlCOomFe0IGBqX5xE166ahDUe6lK7ErXjg6RF7/CezbQMXSPxM77tHAMquCZPOHlK955+iA8VZX/u49IcOn/Mu/168OsGTTPk5Y+SjHlWxid9KJbBnw3wz7/vUALHnz8ZDT6ltel2WdV7KJXR8d2/qBxg3MxqxTh2U1yg8DaVWaXSiY2QXA74FY4Ann3IwoN6lR9fveddw73zHl9Z+RmLeO0va9uK9oAvuLy3ho3k1Y0K97N+8mphT+gDvavkm3evQuKM0PfZ/E/k3w74eJDREkvPQD4q74y1HllX/9DxxG3MQ/hwyfuCPCJ27cbMrm/BjMSBj/x6Omlbx4DYPi25Aw8Y/Q4ywyNn9I+zk38EXhZiCWgVteITFoWtrcG1m6IZsBZctJmvjYYeUfb/yA00qWkDTx0ery1Ln/zRJvk/t/OYs2R0z7aONHnFbyyVHlDa0z7MQOjReYjVmnjsuyZhbyDanTHH4YRHs7G5Vzrtm8CATBeuAkIAH4HOgXbv6hQ4e6hsrOzm5w3WP12mdb3XcfzHE9p77pvvtgTvX3Ne8+6dwjZzo3rb1zj5zp1rz7pBtx/z/cLXf93FU+NNC5DQudKy9zbsNCV/nQQLf33j6BsmAbFrpD008IWZ57b19XeXf7wDKClZe5yrvTwpbXNC1Uubs7LfAKNW1615Btc9O7hp/2v93qVV4x/XhXMT30tMowdcqm93Cl03uEXl6YOsXTe7qy354Upk73kOWlM3q50hm96lWn5L4+ruS+0P/W4epU/G/o/waK7+/niu/vV686RQ/0d0UP9A89bXpPV3p/38P+2yy9v69b9dxtbtXzt7uSI6aV3N/Xrfjd/wtZvurFu9yqF+86etoDfd3nD41zJQ8cXb7sofEhy1e8/Gu34uXfuJIH+h0xrZ/77OHLXfER5cUP9HOfz/mt+3zOb0NOW/L7K0KWf/a337nP/va7kNM++f2VIcuXvjbLLX1tVshpH826OnT5H651xVX/Bl550QP93eI3/s81BLDEhfs7HG5CNF7AWcCCoO93AneGm7+lhkIor3221X3rvvfdv9ftdmXlFe7f63a7b933fo2BMeXuX7ryBwcc9h9K+YMD3LO/uCxkiNx818/dlnsH1StIttw7qN51tt07wG2/N/QfkfAB075BgdVYQdac69QYsg0pb8w6jRnyjfjDoMnWH+Xt3Pnb01xD1BQKze3wUTdgS9D3rcCZwTOY2fXA9QAZGRnk5OQ0aEUFBQUNrhsJacBF3SuZ+vJSth4sp3tqHBedGEta3lq+nVHODxf34IHL36y+mun2l5dx6nHd+M1+Y2rQoagZhZfyduLZDB+wjVOC7pNYO+BWPlvcjacqYrgrxDmNV8rO4vIQ5U+5SwDqVeeJGuqEO3eyK7EHAF1CTKtITCWuHuW7Ek+s97J2JgTqdK1nnQpHyAsHKhJC19kWH1hP/eoE9k2oQ4jlYeqEK98Z3w0DMsKsPzZEeW788QB0rschzMqyYgBiQl08UVoQ+qIKr07IaeHqNOayyoqab50w5ceVbGr0v2PNLRRq5Zx7HHgcYNiwYW7kyJENWk5OTg4NrRspI4GpYcr7Ltt22NVMd4zpy9isbsxbNoCLs7/NupICelUmM/n7vRgMXPdOPPeN/yZEpsxdzm1j+gADuHd+3OHnNIonUDF4PPeumntUedb3/wug0er065rK9+f+N23GP1odFsVz/5utA28GIC3EtM9TvsNp9ShvyLK2DQrUaV/POu+u2hnywoE5ZWdxWYjy5+IuA6hXnT83oE648qfjJoZd1ith6jwZd0XYOuFCfndSIPxChk+YkM1tQJ3GXFZuUmazrROufHfSiY3+d8xcM3oQjJmdBUxzzn3P+34ngHPut6HmHzZsmFuyZEmoSbVqjqHQmOYt28bs7HXVITJ5VK/qq6HCTWuqOs3lJGNj1Jm3bBvL5j/BlHZvfhN+hd+nov94YlfNPao868JAYEa6TlOtv1/XVL6/98mjAnPVqYGQ7f/lrKNDNumMwIn7RqjTmMtqznVqWlZDTjab2VLn3LCQ05pZKMQBXwHnA9uAxcAPnHOrQs2vUDg2ft8HjbX90Q7ZaK8/2sEc7fU3h+2srxYTCgBmdiHwMIErkZ5yzk0PN69C4dj4fR/4fftB+8Cv219TKDS7cwrOufnA/Gi3Q0TEjzR0toiIVFMoiIhINYWCiIhUUyiIiEi1Znf1UX2Y2W5gUwOrdwL2NGJzWiK/7wO/bz9oH/h1+090zh0XakKLDoVjYWZLwl2S5Rd+3wd+337QPvD79oeiw0ciIlJNoSAiItX8HAqPR7sBzYDf94Hftx+0D/y+/Ufx7TkFERE5mp97CiIicgSFgoiIVPNlKJjZBWa2xszWmVmo59q0Cmb2lJnlmtnKoLIOZvauma313tO9cjOzWd4+WW5mQ6LX8sZhZieYWbaZfWFmq8zsFq/cF/vAzJLM7BMz+9zb/nu88p5m9rG3nX81swSvPNH7vs6bnhnN9jcWM4s1s8/M7E3vu6+2v758FwpmFgvMBsYA/YBJZtYvuq2KmGeAC44omwq875zrDbzPNw97GwP09l7XA481URsjqRz4mXOuHzAcmOz9W/tlH5QC33bOnQZkAReY2XDgPuAh51wvYD9wnTf/dcB+r/whb77W4BZgddB3v21//YR7eHNrfQFnAQuCvt8J3BntdkVwezOBlUHf1wBdvc9dgTXe5/8DJoWar7W8gHnAd/24D4C2wKcEnnm+B4jzyqv/fwAWAGd5n+O8+SzabT/G7e5OIPi/DbwJmJ+2vyEv3/UUgG7AlqDvW70yv8hwzu3wPu8EMrzPrXq/eIcCBgMf46N94B06WQbkAu8C64E851y5N0vwNlZvvzf9ANCxaVvc6B4G7gAqve8d8df215sfQ0E8LvCTqNVfk2xmycBc4Fbn3MHgaa19HzjnKpxzWQR+MZ8BnBrlJjUZM/s+kOucWxrttrQkfgyFbcAJQd+7e2V+scvMugJ477leeavcL2YWTyAQXnDO/c0r9tU+AHDO5QHZBA6XtPeehw6Hb2P19nvT04C9TdzUxnQOcLGZbQReInAI6ff4Z/sbxI+hsBjo7V2BkABcAbwe5TY1pdeBa7zP1xA4zl5VfrV3Bc5w4EDQIZYWycwMeBJY7Zx7MGiSL/aBmR1nZu29z20InE9ZTSAcJnizHbn9VftlAvAPryfVIjnn7nTOdXfOZRL4//wfzrkr8cn2N1i0T2pE4wVcCHxF4PjqXdFuTwS380VgB3CIwLHT6wgcI30fWAu8B3Tw5jUCV2WtB1YAw6Ld/kbY/m8RODS0HFjmvS70yz4ABgGfedu/EviVV34S8AmwDngFSPTKk7zv67zpJ0V7GxpxX4wE3vTr9tfnpWEuRESkmh8PH4mISBgKBRERqaZQEBGRagoFERGpplAQEZFqCgWREMyswsyWBb0abTRdM8sMHrlWpDmJq30WEV8qdoHhIUR8RT0FkXows41mdr+ZrfCeVdDLK880s394z2F438x6eOUZZvaq90yDz83sbG9RsWb2J+85B+94dxxjZjd7z39YbmYvRWkzxccUCiKhtTni8NHEoGkHnHMDgUcIjMIJ8AfgWefcIOAFYJZXPgtY6ALPNBgCrPLKewOznXP9gTxgvFc+FRjsLeeGSG2cSDi6o1kkBDMrcM4lhyjfSODBNRu8wfZ2Ouc6mtkeAs9eOOSV73DOdTKz3UB351xp0DIygXdd4CE/mNkUIN45d6+Z/R0oAF4DXnPOFUR4U0UOo56CSP25MJ/rozTocwXfnN+7iMD4S0OAxUGjeYo0CYWCSP1NDHr/0Pv8AYGROAGuBP7pfX4fuBGqH3iTFm6hZhYDnOCcywamEBi6+ajeikgk6VeISGhtvCeWVfm7c67qstR0M1tO4Nf+JK/sJ8DTZnY7sBv4oVd+C/C4mV1HoEdwI4GRa0OJBZ73gsOAWS7wHASRJqNzCiL14J1TGOac2xPttohEgg4fiYhINfUURESkmnoKIiJSTaEgIiLVFAoiIlJNoSAiItUUCiIiUu3/A9HBeqvNizQ6AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "RGywEvxLvtLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manager.save_models(\n",
        "    {\n",
        "        'FFNN': ffnn\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "RJrWpXaslyWo"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}